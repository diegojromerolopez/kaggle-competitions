{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columnas that have nan values\n",
    "columns_without_nans = []\n",
    "columns_with_nans = []\n",
    "for column in train_df.columns:\n",
    "    num_nans = train_df[column].isnull().values.sum()\n",
    "    if num_nans > 0:\n",
    "        print(\"{} (type {}): {} nans\".format(column, train_df[column].dtype, num_nans))\n",
    "        columns_with_nans.append(column)\n",
    "    else:\n",
    "        columns_without_nans.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "for column in columns_without_nans:\n",
    "    column_type = train_df[column].dtype\n",
    "    if column_type == \"object\":\n",
    "        categorical_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categorical columns: {}\".format(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_quality_columns(df):\n",
    "    categorical_quality_columns = [\n",
    "        \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\", \"KitchenQual\",\n",
    "        \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"PoolQC\"\n",
    "    ]\n",
    "    quality_labels= {\n",
    "        \"Ex\": 5,\n",
    "        \"Gd\": 4,\n",
    "        \"TA\": 3,\n",
    "        \"Fa\": 2,\n",
    "        \"Po\": 1,\n",
    "        \"NA\": 0\n",
    "    }\n",
    "    _encode_columns(quality_labels, categorical_quality_columns, df)\n",
    "\n",
    "    \n",
    "def encode_basement_rating_columns(df):\n",
    "    categorical_basement_rating_columns = [\n",
    "        \"BsmtFinType1\", \"BsmtFinType2\"\n",
    "    ]\n",
    "    basement_rating_label = {\n",
    "        \"GLQ\": 6,\n",
    "        \"ALQ\": 5,\n",
    "        \"BLQ\": 4,\n",
    "        \"Rec\": 3,\n",
    "        \"LwQ\": 2,\n",
    "        \"Unf\": 1,\n",
    "        \"NA\": 0\n",
    "    }\n",
    "    _encode_columns(basement_rating_label, categorical_basement_rating_columns, df)\n",
    "\n",
    "\n",
    "def encode_garage_finish_column(df):\n",
    "    garage_finish_columns = [\n",
    "        \"GarageFinish\"\n",
    "    ]\n",
    "    garage_finish_label= {\n",
    "        \"Fin\": 3,\n",
    "        \"RFn\": 2,\n",
    "        \"Unf\": 1,\n",
    "        \"NA\": 0\n",
    "    }\n",
    "    _encode_columns(garage_finish_label, garage_finish_columns, df)\n",
    "\n",
    "    \n",
    "def encode_utilities(df):\n",
    "    columns = [\n",
    "        \"Utilities\"\n",
    "    ]\n",
    "    utilities_labels= {\n",
    "        \"AllPub\": 3,\n",
    "        \"NoSewr\": 2,\n",
    "        \"NoSeWa\": 1,\n",
    "        \"ELO\": 0\n",
    "    }\n",
    "    _encode_columns(utilities_labels, columns, df)\n",
    "\n",
    "\n",
    "def _encode_columns(label_encoding_correspondence, columns, df):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].map(lambda cell: label_encoding_correspondence.get(cell, 0))\n",
    "        df[column] = df[column].astype(int)\n",
    "\n",
    "\n",
    "def encode_columns(df):\n",
    "    encode_quality_columns(df)\n",
    "    encode_basement_rating_columns(df)\n",
    "    encode_garage_finish_column(df)\n",
    "\n",
    "\n",
    "encode_columns(train_df)\n",
    "encode_columns(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columnas that have nan values\n",
    "columns_without_nans = []\n",
    "columns_with_nans = []\n",
    "for column in train_df.columns:\n",
    "    num_nans = train_df[column].isnull().values.sum()\n",
    "    if num_nans > 0:\n",
    "        print(\"{} (type {}): {} nans\".format(column, train_df[column].dtype, num_nans))\n",
    "        columns_with_nans.append(column)\n",
    "    else:\n",
    "        columns_without_nans.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the categorical columns, creating dummy (1/0) columns\n",
    "expanded_train_df = pd.get_dummies(train_df, dummy_na=True)\n",
    "expanded_test_df = pd.get_dummies(test_df, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case any column of test is not present in train, set it to zero\n",
    "all_columns = set(expanded_train_df.columns).union(set(expanded_test_df.columns)) - set([\"SalePrice\"])\n",
    "for column in all_columns:\n",
    "    if column not in expanded_train_df.columns:\n",
    "        expanded_train_df[column] = 0\n",
    "    if column not in expanded_test_df.columns:\n",
    "        expanded_test_df[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each NAN fill it to the median value of that column\n",
    "ready_train_df = expanded_train_df.fillna(expanded_train_df.median())\n",
    "ready_test_df = expanded_test_df.fillna(expanded_test_df.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df):\n",
    "    # Built area in sq. feet: LotArea - 1stFlrSF\n",
    "    df[\"BuiltAreaSF\"] = df[\"LotArea\"] - df[\"1stFlrSF\"]\n",
    "    # Total home area: 1stFlrSF + 2stFlSF + TotalBsmtSF\n",
    "    df[\"TotalHomeAreaSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] + df[\"TotalBsmtSF\"]\n",
    "\n",
    "add_new_features(ready_train_df)\n",
    "add_new_features(ready_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All transforming process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input_data(df):\n",
    "    encode_columns(df)\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    add_new_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = ready_train_df.corr()\n",
    "correlation_values = correlation_matrix[\"SalePrice\"].sort_values(ascending=False)\n",
    "print(correlation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_correlation_pairs = []\n",
    "for feature, value in correlation_values.items():\n",
    "    feature_correlation_pairs.append((feature, abs(value)))\n",
    "    \n",
    "sorted_feature_correlation_pairs = sorted(feature_correlation_pairs, key=lambda pair: pair[1], reverse=True)    \n",
    "\n",
    "most_correlated_features = [\n",
    "    feature_correlation_pair[0]\n",
    "    for feature_correlation_pair in sorted_feature_correlation_pairs \n",
    "]\n",
    "for sorted_feature_correlation_pair in sorted_feature_correlation_pairs:\n",
    "    print(sorted_feature_correlation_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_best_features_to_keep = 25 \n",
    "\n",
    "def drop_worst_features(df, most_correlated_features):\n",
    "    print(\"Droping {} columns\".format(len(most_correlated_features[number_of_best_features_to_keep:])))\n",
    "    return df.drop(most_correlated_features[number_of_best_features_to_keep:], axis=1)\n",
    "\n",
    "final_train_df = drop_worst_features(ready_train_df, most_correlated_features)\n",
    "final_test_df = drop_worst_features(ready_test_df, most_correlated_features)\n",
    "\n",
    "print(\"{} selected columns: {}\".format(len(final_train_df.columns), final_train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input data to regressors\n",
    "y = final_train_df[\"SalePrice\"].values\n",
    "\n",
    "X = final_train_df.drop(\"SalePrice\", axis=1).values\n",
    "\n",
    "test_x = final_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y.shape\n",
    "print X.shape\n",
    "print test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull runner\n",
    "class RegressorRunner(object):\n",
    "    \n",
    "    def __init__(self, pipeline, parameters, cv=5, debug=True):\n",
    "        self.pipeline = pipeline\n",
    "        self.parameters = parameters\n",
    "        self.grid_search = GridSearchCV(self.pipeline, self.parameters, cv=cv)\n",
    "        self.debug = debug\n",
    "        self.prediction = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.grid_search.fit(X, y)\n",
    "\n",
    "    @property\n",
    "    def best_params(self):\n",
    "        return self.grid_search.best_params_\n",
    "    \n",
    "    @property\n",
    "    def best_estimator(self):\n",
    "        return self.grid_search.best_estimator_\n",
    "    \n",
    "    def get_scores(self, X, y, num_folds=5):\n",
    "        scores = cross_val_score(self.grid_search.best_estimator_, X, y, cv=num_folds)\n",
    "        return scores\n",
    "    \n",
    "    @property\n",
    "    def feature_importances(self):\n",
    "        classifier_step_index = 0\n",
    "        for step_name, step_process in self.grid_search.best_estimator_.steps:\n",
    "            if step_name == \"regressor\":\n",
    "                break\n",
    "            classifier_step_index += 1\n",
    "        feature_importances = self.grid_search.best_estimator_.steps[classifier_step_index][1].feature_importances_\n",
    "        return sorted(zip(feature_importances, selected_features), reverse=True)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.prediction is None:\n",
    "            self.prediction = self.grid_search.predict(X_test)\n",
    "        return self.prediction\n",
    "    \n",
    "    def mean_squared_error(self, X, y):\n",
    "        y_predicted = self.grid_search.predict(X)\n",
    "        return mean_squared_error(y, y_predicted)\n",
    "\n",
    "    def apply_predicition_to_df(self, X_test, test_df, output_filename, estimator_for_negatives=None):\n",
    "        if self.prediction is None:\n",
    "            self.predict(X_test)\n",
    "        # Add the prediction to the test dataset\n",
    "        estimated_test_df = test_df.assign(SalePrice=list(self.prediction))\n",
    "        \n",
    "        # Count nevative prices\n",
    "        if self.debug:\n",
    "            number_of_negative_prices = 0\n",
    "            for i, row in estimated_test_df.iterrows():\n",
    "                    if row[\"SalePrice\"] <= 0:\n",
    "                        number_of_negative_prices += 1\n",
    "            print(\"{} houses have negative prices of {}\".format(number_of_negative_prices, estimated_test_df.shape[0]))\n",
    "        \n",
    "        # Assign correct values to negative prices\n",
    "        if estimator_for_negatives is None:\n",
    "            # IMPORTANT PATCH: NO SALE PRICE MUST BE NEGATIVE\n",
    "            # In case there is any negative SalePrice, set it to 0\n",
    "            estimated_test_df[\"SalePrice\"] = estimated_test_df[\"SalePrice\"].map(\n",
    "                lambda sale_price: np.nan if sale_price < 0 else sale_price\n",
    "            )\n",
    "\n",
    "            estimated_test_df[\"SalePrice\"].fillna(estimated_test_df[\"SalePrice\"].median(), inplace=True)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for i, row in estimated_test_df.iterrows():\n",
    "                if row[\"SalePrice\"] <= 0:\n",
    "                    row_df = pd.DataFrame(row, columns=estimated_test_df.columns)\n",
    "                    row_df_X = drop_worst_features(transform_input_data(row_df).drop(\"SalePrice\", axis=1)).values\n",
    "                    positive_sale_price_y = estimator_for_negatives.predict(row_df_X)\n",
    "                    estimated_test_df.set_value(i, 'SalePrice', positive_sale_price_y[0])\n",
    "        \n",
    "        # Save \n",
    "        estimated_test_df.to_csv(output_filename, columns=[\"Id\", \"SalePrice\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'regressor__n_neighbors': [3, 5, 7, 10],\n",
    "    'regressor__weights': [\"uniform\", \"distance\"],\n",
    "    'regressor__algorithm': [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    'regressor__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "knn_runner = RegressorRunner(pipeline=pipeline, parameters=parameters)\n",
    "\n",
    "knn_runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for KNN regression: \")\n",
    "print (knn_runner.best_params)\n",
    "\n",
    "scores = knn_runner.get_scores(X, y)\n",
    "print(\"Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = knn_runner.mean_squared_error(X, y)\n",
    "print(\"RMSE of training data {}\".format(rmse))\n",
    "\n",
    "knn_runner.apply_predicition_to_df(test_x, test_df, output_filename=\"results/test_estimated_with_knn.csv\")\n",
    "\n",
    "knn_estimator = knn_runner.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "runner = RegressorRunner(pipeline=pipeline, parameters=parameters)\n",
    "\n",
    "runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for Linear regression: \")\n",
    "print (runner.best_params)\n",
    "\n",
    "scores = runner.get_scores(X, y)\n",
    "print(\"Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = runner.mean_squared_error(X, y)\n",
    "print(\"RMSE of training data {}\".format(rmse))\n",
    "\n",
    "runner.apply_predicition_to_df(test_x, test_df, estimator_for_negatives=None, output_filename=\"results/test_estimated_with_ln.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regressor\n",
    "for degree in [2, 3, 4, 5]:\n",
    "    print(\"Polynomial regression {}: \".format(degree))\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "    runner = RegressorRunner(pipeline=pipeline, parameters={})\n",
    "\n",
    "    runner.fit(X, y)\n",
    "\n",
    "    print (\"- Best parameters found for polynomial regression {}: {}\".format(degree, runner.best_params))\n",
    "\n",
    "    scores = runner.get_scores(X, y)\n",
    "    print(\"- Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "    rmse = runner.mean_squared_error(X, y)\n",
    "    print(\"- RMSE of training data {}\".format(rmse))\n",
    "    \n",
    "    runner.apply_predicition_to_df(test_x, test_df, output_filename=\"results/test_estimated_with_poly_{}.csv\".format(degree))\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defision tree regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'regressor__criterion': [\"mse\", \"mae\", \"friedman_mse\"],\n",
    "    'regressor__random_state': [42],\n",
    "    'regressor__max_depth': [100, 300, 500, 1000],\n",
    "    'regressor__max_features': ['sqrt', 'auto', 'log2', None],\n",
    "    'regressor__min_samples_split': [2, 3, 10],\n",
    "    'regressor__min_samples_leaf': [1, 3, 10],\n",
    "    'regressor__presort': [True, False]\n",
    "}\n",
    "\n",
    "runner = RegressorRunner(pipeline=pipeline, parameters=parameters)\n",
    "\n",
    "runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for Decision Tree regression: \")\n",
    "print (runner.best_params)\n",
    "\n",
    "print(\"- Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = runner.mean_squared_error(X, y)\n",
    "print(\"- RMSE of training data {}\".format(rmse))\n",
    "\n",
    "runner.apply_predicition_to_df(test_x, test_df, estimator_for_negatives=None, output_filename=\"results/test_estimated_with_dt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Process regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", GaussianProcessRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'regressor__random_state': [1,2,3,4,5]\n",
    "}\n",
    "\n",
    "runner = RegressorRunner(pipeline=pipeline, parameters=parameters)\n",
    "\n",
    "runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for Gaussian Process regression: \")\n",
    "print (runner.best_params)\n",
    "\n",
    "print(\"- Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = runner.mean_squared_error(X, y)\n",
    "print(\"- RMSE of training data {}\".format(rmse))\n",
    "\n",
    "runner.apply_predicition_to_df(test_x, test_df, estimator_for_negatives=None, output_filename=\"results/test_estimated_with_gp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "best_parameters = {\n",
    "    'regressor__n_estimators': [100], \n",
    "    'regressor__criterion': [\"mae\"],\n",
    "    'regressor__max_features': ['sqrt'],\n",
    "    'regressor__min_samples_split': [3],\n",
    "    'regressor__min_samples_leaf': [1],\n",
    "    'regressor__bootstrap': [False],\n",
    "    'regressor__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'regressor__n_estimators': [10, 20, 30, 40, 100], \n",
    "    'regressor__criterion': [\"mse\", \"mae\"],\n",
    "    'regressor__max_features': ['sqrt', 'auto', 'log2', None],\n",
    "    'regressor__min_samples_split': [2, 3, 10],\n",
    "    'regressor__min_samples_leaf': [1, 3, 10],\n",
    "    'regressor__bootstrap': [True, False],\n",
    "    'regressor__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "runner = RegressorRunner(pipeline=pipeline, parameters=best_parameters)\n",
    "\n",
    "runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for RF regression: \")\n",
    "print (runner.best_params)\n",
    "\n",
    "print(\"- Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = runner.mean_squared_error(X, y)\n",
    "print(\"- RMSE of training data {}\".format(rmse))\n",
    "\n",
    "runner.apply_predicition_to_df(test_x, test_df, estimator_for_negatives=None, output_filename=\"results/test_estimated_with_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM regressor\n",
    "pipeline = Pipeline([\n",
    "    (\"regressor\", SVR())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'regressor__C': [1, 2], \n",
    "    'regressor__epsilon': [0.1, 0.05],\n",
    "    'regressor__kernel': ['rbf', 'linear', 'poly', \"sigmoid\", \"precomputed\"]\n",
    "}\n",
    "\n",
    "runner = RegressorRunner(pipeline=pipeline, parameters=parameters)\n",
    "\n",
    "runner.fit(X, y)\n",
    "\n",
    "print (\"Best parameters found for SVM regression: \")\n",
    "print (runner.best_params)\n",
    "\n",
    "print(\"- Mean of CV scores data {}\".format(np.mean(scores)))\n",
    "\n",
    "rmse = runner.mean_squared_error(X, y)\n",
    "print(\"- RMSE of training data {}\".format(rmse))\n",
    "\n",
    "runner.apply_predicition_to_df(test_x, test_df, estimator_for_negatives=None, output_filename=\"results/test_estimated_with_SVM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
